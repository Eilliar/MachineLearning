{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Kaggle Tutorial for Machine Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple tutorial on how to get started with Machine Learning and Kaggle Competitions.\n",
    "\n",
    "Necessary modules to run this notebook:\n",
    "* [Numpy](http://www.numpy.org/)\n",
    "* [Scikit-Learn](http://scikit-learn.org/stable/)\n",
    "* [Pandas](http://pandas.pydata.org/)\n",
    "\n",
    "We're going to use the [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic) dataset, from [Kaggle](https://www.kaggle.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the Numpy library\n",
    "import numpy as np\n",
    "#Import 'tree' from scikit-learn library\n",
    "from sklearn import tree\n",
    "# Import the Pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Let's not worry about 'pandas copy vs view warnings' for now...\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data from the web. We'll be using the Kaggle Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_path = \"train.csv\"\n",
    "train = pd.read_csv(train_path)\n",
    "\n",
    "test_path = \"test.csv\"\n",
    "test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Print the `head` of the train and test dataframes\n",
    "train.head()\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some usefull information about our test and train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Train data set shape: \", train.shape\n",
    "print \"Test data set shape: \", test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VARIABLE DESCRIPTIONS:**\n",
    "\n",
    "* survival: Survival (0 = No; 1 = Yes)\n",
    "\n",
    "* pclass: Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "* name: Name\n",
    "* sex: Sex\n",
    "* age: Age\n",
    "* sibsp: Number of Siblings/Spouses Aboard\n",
    "* parch: Number of Parents/Children Aboard\n",
    "* ticket: Ticket Number\n",
    "* fare: Passenger Fare\n",
    "* cabin: Cabin\n",
    "* embarked: Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a nice feature to get general information about your data, the [describe()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many survived on the train dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[\"Survived\"].value_counts(normalize = True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Males that survived vs males that passed away\n",
    "print(\"Males that survived vs males that passed away:\")\n",
    "print(train[\"Survived\"][train[\"Sex\"]=='male'].value_counts())\n",
    "# Normalized male survival\n",
    "print(\"\\nMales that survived vs males that passed away (Normalized):\")\n",
    "print(train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Females that survived vs Females that passed away\n",
    "print(\"Females that survived vs females that passed away:\")\n",
    "print(train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts())\n",
    "# Normalized female survival\n",
    "print(\"\\nFemales that survived vs females that passed away (Normalized):\")\n",
    "print(train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if data consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in list(train.columns.values):\n",
    "    print \"Number of missing data on {}: {}\".format(col,train[col].isnull().values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Some data treatment\n",
    "\n",
    "What if you want to create new attributes instead of using the providing ones? This is called [feature engineering](http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the column Child and assign to 'NaN'\n",
    "train[\"Child\"] = float('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign 1 to passengers under 18, 0 to those 18 or older. Print the new column.\n",
    "train.Child[train[\"Age\"] < 18] = 1\n",
    "train.Child[train[\"Age\"] >= 18] = 0\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print normalized Survival Rates for passengers under 18\n",
    "print(\"Survival Rate for under 18:\")\n",
    "print(train[\"Survived\"][train[\"Child\"] == 1].value_counts(normalize = True))\n",
    "\n",
    "# Print normalized Survival Rates for passengers 18 or older\n",
    "print(\"\\nSurvival Rate for 18 or older:\")\n",
    "print(train[\"Survived\"][train[\"Child\"] == 0].value_counts(normalize =True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert the male and female groups to integer form\n",
    "train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\n",
    "train[\"Sex\"][train[\"Sex\"] == \"female\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Impute the Embarked variable\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert the Embarked classes to integer form\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a model that will use the following features:\n",
    "\n",
    "* Pclass\n",
    "* Sex\n",
    "* Age\n",
    "* Fare\n",
    "\n",
    "How many missing entries do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Number of missing entries: {}\".format(train[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].isnull().values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisely the number of missing points for the **Age ** feature. One first approach is to drop those rows (entries) and try to train a model on the remaining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train2 = train[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Survived\"]]\n",
    "train2.dropna(axis = 0, inplace = True)\n",
    "\n",
    "print \"Train shape: {}\".format(train.shape)\n",
    "print \"Train2 shape: {}\".format(train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the target and features numpy arrays: target, features_one\n",
    "target = train2[\"Survived\"].values\n",
    "features_one = train2[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Let's start some Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build our [Decision Tree Model](http://scikit-learn.org/stable/modules/tree.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop NaN values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit your first decision tree: my_tree_one\n",
    "my_tree_one = tree.DecisionTreeClassifier()\n",
    "my_tree_one = my_tree_one.fit(features_one, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `feature_importances_` attribute make it simple to interpret the significance of the features we've included in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at the importance and score of the included features\n",
    "feature_list = [\"Pclass\", \"Sex\", \"Age\", \"Fare\"]\n",
    "importances = my_tree_one.feature_importances_\n",
    "\n",
    "for k in range(0,len(feature_list)):\n",
    "    print \"Feature: {}\\t-> Importance: {}\".format(feature_list[k], importances[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(my_tree_one.score(features_one, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Make some predictions\n",
    "\n",
    "Once we have our model, we can apply it to our test set and see the results...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in list(test.columns.values):\n",
    "    print \"Number of missing data on {}: {}\".format(col,test[col].isnull().values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impute the missing value with the median\n",
    "test.Fare[152] = test.Fare.median()\n",
    "test.Age = test.Age.fillna(test.Age.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert the male and female groups to integer form\n",
    "test[\"Sex\"][test[\"Sex\"] == \"male\"] = 0\n",
    "test[\"Sex\"][test[\"Sex\"] == \"female\"] = 1\n",
    "#Impute the Embarked variable\n",
    "test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "#Convert the Embarked classes to integer form\n",
    "test[\"Embarked\"][test[\"Embarked\"] == \"S\"] = 0\n",
    "test[\"Embarked\"][test[\"Embarked\"] == \"C\"] = 1\n",
    "test[\"Embarked\"][test[\"Embarked\"] == \"Q\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract the features from the test set: Pclass, Sex, Age, and Fare.\n",
    "test_features = test[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values\n",
    "\n",
    "# Make your prediction using the test set\n",
    "my_prediction = my_tree_one.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions\n",
    "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [\"Survived\"])\n",
    "print(my_solution)\n",
    "\n",
    "# Check that your data frame has 418 entries\n",
    "print(my_solution.shape)\n",
    "\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution.to_csv(\"my_solution_one.csv\", index_label = [\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Overfitting and how to control it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new array with the added features: features_two\n",
    "train3 = train[[\"Pclass\",\"Age\",\"Sex\",\"Fare\", \"SibSp\",\"Parch\", \"Embarked\"]]\n",
    "train3.dropna(axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_two = train3.values\n",
    "\n",
    "#Control overfitting by setting \"max_depth\" to 10 and \"min_samples_split\" to 5 : my_tree_two\n",
    "max_depth = 10\n",
    "min_samples_split = 5\n",
    "my_tree_two = tree.DecisionTreeClassifier(max_depth = max_depth, min_samples_split = min_samples_split, random_state = 1)\n",
    "my_tree_two = my_tree_two.fit(features_two, target)\n",
    "\n",
    "#Print the score of the new decison tree\n",
    "print(\"Second model score: {}\".format(my_tree_two.score(features_two, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at the importance and score of the included features\n",
    "feature_list = [\"Pclass\",\"Age\",\"Sex\",\"Fare\", \"SibSp\",\"Parch\", \"Embarked\"]\n",
    "importances = my_tree_two.feature_importances_\n",
    "\n",
    "for k in range(0,len(feature_list)):\n",
    "    print \"Feature: {}\\t-> Importance: {}\".format(feature_list[k], importances[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract the features from the test set: Pclass, Sex, Age, and Fare.\n",
    "test_features = test[[\"Pclass\",\"Age\",\"Sex\",\"Fare\", \"SibSp\",\"Parch\", \"Embarked\"]].values\n",
    "\n",
    "# Make your prediction using the test set\n",
    "my_prediction2 = my_tree_two.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_solution2 = pd.DataFrame(my_prediction2, PassengerId, columns = [\"Survived\"])\n",
    "print(my_solution2)\n",
    "\n",
    "# Check that your data frame has 418 entries\n",
    "print(my_solution2.shape)\n",
    "\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution2.to_csv(\"my_solution_two.csv\", index_label = [\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create train_two with the newly defined feature\n",
    "train_two = train.copy()\n",
    "train_two[\"family_size\"] = train_two.SibSp + train_two.Parch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train3 = train_two[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"SibSp\", \"Parch\", \"family_size\"]]\n",
    "for col in list(train3.columns.values):\n",
    "    print \"Number of missing data on {}: {}\".format(col,train3[col].isnull().values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train3.Age = train3.Age.fillna(train.Age.median())\n",
    "target = train.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new feature set and add the new feature\n",
    "features_three = train3.values\n",
    "\n",
    "# Define the tree classifier, then fit the model\n",
    "my_tree_three = tree.DecisionTreeClassifier(max_depth = max_depth, min_samples_split = min_samples_split, random_state = 1)\n",
    "my_tree_three = my_tree_three.fit(features_three, target)\n",
    "\n",
    "# Print the score of this decision tree\n",
    "print(my_tree_three.score(features_three, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_three = test.copy()\n",
    "test_three[\"family_size\"] = test_three.SibSp + test_three.Parch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the features from the test set: Pclass, Sex, Age, and Fare.\n",
    "test_features = test_three[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"SibSp\", \"Parch\", \"family_size\"]].values\n",
    "\n",
    "# Make your prediction using the test set\n",
    "my_prediction3 = my_tree_three.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_solution3 = pd.DataFrame(my_prediction3, PassengerId, columns = [\"Survived\"])\n",
    "\n",
    "# Check that your data frame has 418 entries\n",
    "print(my_solution3.shape)\n",
    "\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution3.to_csv(\"my_solution_three.csv\", index_label = [\"PassengerId\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
